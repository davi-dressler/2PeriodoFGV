{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccb111e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Nota  Temporadas  Episódios\n",
      "Ted Lasso              9           4         34\n",
      "Parks & Recreation     9           7        125\n",
      "Vikings                9           6         89\n",
      "Suits                  8           9        134\n",
      "Breaking Bad          10           5         62\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "indices = [\"Ted Lasso\", \"Parks & Recreation\", \"Vikings\", \"Suits\", \"Breaking Bad\"]\n",
    "colunas = [\"Nota\", \"Temporadas\", \"Episódios\"]\n",
    "dados = [[9, 4, 34], [9, 7, 125], [9, 6, 89], [8, 9, 134], [10, 5, 62]]\n",
    "\n",
    "df = pd.DataFrame(dados, index=indices, columns=colunas)\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b010783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notas:\n",
      "Ted Lasso              9\n",
      "Parks & Recreation     9\n",
      "Vikings                9\n",
      "Suits                  8\n",
      "Breaking Bad          10\n",
      "Name: Nota, dtype: int64 \n",
      "\n",
      "Temporadas:\n",
      "Ted Lasso             4\n",
      "Parks & Recreation    7\n",
      "Vikings               6\n",
      "Suits                 9\n",
      "Breaking Bad          5\n",
      "Name: Temporadas, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Notas:\") #Seleção de uma coluna\n",
    "print (df[\"Nota\"], \"\\n\")\n",
    "print (\"Temporadas:\")\n",
    "print (df[\"Temporadas\"], \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6fc582e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notas e Episódios:\n",
      "                    Nota  Episódios\n",
      "Ted Lasso              9         34\n",
      "Parks & Recreation     9        125\n",
      "Vikings                9         89\n",
      "Suits                  8        134\n",
      "Breaking Bad          10         62 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Notas e Episódios:\") #Seleção de duas colunas\n",
    "print (df[[\"Nota\", \"Episódios\"]], \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d4a6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suits {loc}:\n",
      "Nota            8\n",
      "Temporadas      9\n",
      "Episódios     134\n",
      "Name: Suits, dtype: int64\n",
      "Suits {loc}:\n",
      "Nota            8\n",
      "Temporadas      9\n",
      "Episódios     134\n",
      "Name: Suits, dtype: int64\n",
      "########################################\n",
      "Notas de Suits: 8\n",
      "Notas de Suits: 8\n",
      "Notas de Suits: 8\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "print (\"Suits {loc}:\")\n",
    "print (df.loc[\"Suits\"])\n",
    "\n",
    "print (\"Suits {loc}:\")\n",
    "print (df.iloc[3])\n",
    "print (\"#\"*40)\n",
    "\n",
    "print (\"Notas de Suits:\", df.loc[\"Suits\", \"Nota\"]) #primeiro parâmetro: linha, segundo: coluna\n",
    "print (\"Notas de Suits:\", df.iloc[3,0])\n",
    "print (\"Notas de Suits:\", df.at[\"Suits\", \"Nota\"]) #mais rápido\n",
    "print (\"#\"*40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "080ccc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ted Lasso e Parks & Recreation, Nota e Temporada\n",
      "                    Nota  Temporadas\n",
      "Ted Lasso              9           4\n",
      "Parks & Recreation     9           7\n",
      "Usando slice\n",
      "                    Temporadas  Episódios\n",
      "Parks & Recreation           7        125\n",
      "Vikings                      6         89\n",
      "Suits                        9        134\n",
      "                    Nota  Temporadas\n",
      "Ted Lasso              9           4\n",
      "Parks & Recreation     9           7\n",
      "Vikings                9           6\n",
      "Suits                  8           9\n",
      "Breaking Bad          10           5\n",
      "                    Nota  Temporadas  Episódios\n",
      "Ted Lasso              9           4         34\n",
      "Parks & Recreation     9           7        125\n",
      "              Nota  Temporadas  Episódios\n",
      "Suits            8           9        134\n",
      "Breaking Bad    10           5         62\n",
      "Valores únicos de nota:\n",
      "\n",
      "[ 9  8 10]\n",
      "Número de valores únicos de nota:\n",
      "\n",
      "3\n",
      "Contagem:\n",
      "\n",
      "5\n",
      "Contagem de valores:\n",
      "\n",
      "Nota\n",
      "9     3\n",
      "8     1\n",
      "10    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (\"Ted Lasso e Parks & Recreation, Nota e Temporada\")\n",
    "print (df.loc[[\"Ted Lasso\", \"Parks & Recreation\"], [\"Nota\", \"Temporadas\"]])\n",
    "print (\"Usando slice\")\n",
    "print (df.loc[\"Parks & Recreation\":\"Suits\", \"Temporadas\":])\n",
    "print (df.loc[:, [\"Nota\", \"Temporadas\"]])\n",
    "\n",
    "#Operações\n",
    "print (df.head(2))\n",
    "print (df.tail(2))\n",
    "print (\"Valores únicos de nota:\\n\")\n",
    "print (df[\"Nota\"].unique())\n",
    "print (\"Número de valores únicos de nota:\\n\")\n",
    "print (df[\"Nota\"].nunique())\n",
    "print (\"Contagem:\\n\")\n",
    "print (df[\"Nota\"].count())\n",
    "print (\"Contagem de valores:\\n\")\n",
    "print (df[\"Nota\"].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5483847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota mínima nos dados: 8\n",
      "Nota máxima nos dados: 10\n",
      "Média das notas nos dados: 9.0\n",
      "Mediana das notas nos dados: 9.0\n"
     ]
    }
   ],
   "source": [
    "print (\"Nota mínima nos dados:\", df[\"Nota\"].min())\n",
    "print (\"Nota máxima nos dados:\", df[\"Nota\"].max())\n",
    "print (\"Média das notas nos dados:\", df[\"Nota\"].mean())\n",
    "print (\"Mediana das notas nos dados:\", df[\"Nota\"].median())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe4088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Nota', 'Temporadas', 'Episódios'], dtype='object')\n",
      "['Nota', 'Temporadas', 'Episódios']\n",
      "['Nota' 'Temporadas' 'Episódios']\n",
      "['Nota' 'Temporadas' 'Episódios']\n",
      "Index(['Ted Lasso', 'Parks & Recreation', 'Vikings', 'Suits', 'Breaking Bad'], dtype='object')\n",
      "['Ted Lasso', 'Parks & Recreation', 'Vikings', 'Suits', 'Breaking Bad']\n",
      "['Ted Lasso' 'Parks & Recreation' 'Vikings' 'Suits' 'Breaking Bad']\n",
      "['Ted Lasso' 'Parks & Recreation' 'Vikings' 'Suits' 'Breaking Bad']\n",
      "                    Nota  Temporadas  Episódios  Coluna extra\n",
      "Ted Lasso              9           4         34           4.5\n",
      "Parks & Recreation     9           7        125           4.5\n",
      "Vikings                9           6         89           4.5\n",
      "Suits                  8           9        134           4.0\n",
      "Breaking Bad          10           5         62           5.0\n",
      "                    Nota  Temporadas  Episódios\n",
      "Ted Lasso              9           4         34\n",
      "Parks & Recreation     9           7        125\n",
      "Vikings                9           6         89\n",
      "Suits                  8           9        134\n",
      "Breaking Bad          10           5         62\n",
      "                    Nota  Temporadas  Episódios\n",
      "Ted Lasso              9           4         34\n",
      "Parks & Recreation     9           7        125\n",
      "Suits                  8           9        134\n",
      "Breaking Bad          10           5         62\n"
     ]
    }
   ],
   "source": [
    "print (df.columns)\n",
    "print (df.columns.to_list()) #listas\n",
    "print (df.columns.to_numpy()) #mais moderno. ndarray\n",
    "print (df.columns.values)\n",
    "\n",
    "print (df.index)\n",
    "print (df.index.to_list()) #listas\n",
    "print (df.index.to_numpy()) #mais moderno. ndarray\n",
    "print (df.index.values)\n",
    "\n",
    "df [\"Coluna extra\"] = df[\"Nota\"]/2 #Nova coluna\n",
    "print (df)\n",
    "\n",
    "df.drop (\"Coluna extra\", axis=1, inplace=True) #apaga a coluna extra\n",
    "print (df)\n",
    "\n",
    "df.drop (\"Vikings\", inplace=True) #apaga a linha escolhida\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee0e8cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         matrícula  idade            nome\n",
      "Aluno 1    2025001     19      João Silva\n",
      "Aluno 2    2025002     21  Maria Oliveira\n",
      "Aluno 3    2025003     20     Pedro Souza\n",
      "Aluno 4    2025004     22       Ana Costa\n"
     ]
    }
   ],
   "source": [
    "indices = [\"Aluno 1\", \"Aluno 2\", \"Aluno 3\", \"Aluno 4\"]\n",
    "colunas = [\"matrícula\", \"idade\", \"nome\"]\n",
    "dados = [\n",
    "    [2025001, 19, 'João Silva'],\n",
    "    [2025002, 21, 'Maria Oliveira'],\n",
    "    [2025003, 20, 'Pedro Souza'],\n",
    "    [2025004, 22, 'Ana Costa']\n",
    "]\n",
    "\n",
    "df2 = pd.DataFrame(dados, index= indices, columns= colunas)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85f7ec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         matrícula  idade   nome\n",
      "Aluno 1      False  False  False\n",
      "Aluno 2      False  False  False\n",
      "Aluno 3      False  False  False\n",
      "Aluno 4      False  False  False\n"
     ]
    }
   ],
   "source": [
    "print(df2.isnull()) #verifica valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f680693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         matrícula  idade            nome\n",
      "Aluno 1    2025001     19      João Silva\n",
      "Aluno 3    2025003     20     Pedro Souza\n",
      "Aluno 2    2025002     21  Maria Oliveira\n",
      "Aluno 4    2025004     22       Ana Costa\n"
     ]
    }
   ],
   "source": [
    "print(df2.sort_values(by= \"idade\")) #Ordena as linhas pela coluna idade (Crescente por padrão)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sort_values(by= \"idade\", ascending= False, inplace= True) #Ordena as linhas pela coluna idade (Decrescente e altera o DataFrame original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4e67d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matrícula</th>\n",
       "      <th>idade</th>\n",
       "      <th>nome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aluno 4</th>\n",
       "      <td>2025004</td>\n",
       "      <td>22</td>\n",
       "      <td>Ana Costa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aluno 2</th>\n",
       "      <td>2025002</td>\n",
       "      <td>21</td>\n",
       "      <td>Maria Oliveira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aluno 3</th>\n",
       "      <td>2025003</td>\n",
       "      <td>20</td>\n",
       "      <td>Pedro Souza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aluno 1</th>\n",
       "      <td>2025001</td>\n",
       "      <td>19</td>\n",
       "      <td>João Silva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         matrícula  idade            nome\n",
       "Aluno 4    2025004     22       Ana Costa\n",
       "Aluno 2    2025002     21  Maria Oliveira\n",
       "Aluno 3    2025003     20     Pedro Souza\n",
       "Aluno 1    2025001     19      João Silva"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f7868eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File aula_pinho.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df3 = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maula_pinho.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df3\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sodre\\2PeriodoFGV\\venv\\Lib\\site-packages\\pandas\\io\\json\\_json.py:791\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient != \u001b[33m\"\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    789\u001b[39m     convert_axes = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m json_reader = \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sodre\\2PeriodoFGV\\venv\\Lib\\site-packages\\pandas\\io\\json\\_json.py:904\u001b[39m, in \u001b[36mJsonReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = filepath_or_buffer\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mujson\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28mself\u001b[39m._preprocess_data(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sodre\\2PeriodoFGV\\venv\\Lib\\site-packages\\pandas\\io\\json\\_json.py:960\u001b[39m, in \u001b[36mJsonReader._get_data_from_filepath\u001b[39m\u001b[34m(self, filepath_or_buffer)\u001b[39m\n\u001b[32m    952\u001b[39m     filepath_or_buffer = \u001b[38;5;28mself\u001b[39m.handles.handle\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    954\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    955\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer.lower().endswith(\n\u001b[32m   (...)\u001b[39m\u001b[32m    958\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[32m    959\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    962\u001b[39m     warnings.warn(\n\u001b[32m    963\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal json to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_json\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    967\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    968\u001b[39m     )\n",
      "\u001b[31mFileNotFoundError\u001b[39m: File aula_pinho.json does not exist"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_json(\"aula_pinho.json\")\n",
    "df3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
